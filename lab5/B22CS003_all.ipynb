{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PART - 1(K-Means Clustering)"
      ],
      "metadata": {
        "id": "IK4TAxg57aM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - A"
      ],
      "metadata": {
        "id": "lSxuFLce74MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## importing necessary libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fkxShazy-f44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## importing the image\n",
        "img = cv2.imread(\"/content/test.png\")\n",
        "rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "xszpYp20Atzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height, width, channels = rgb_image.shape\n",
        "## extracting the pixels from the image\n",
        "rgb_data = []\n",
        "\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "\n",
        "      r, g, b = rgb_image[y, x]\n",
        "      rgb_data.append([r, g, b])"
      ],
      "metadata": {
        "id": "Y9AnhCYOBzrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(rgb_data)  ## total no. of pixels"
      ],
      "metadata": {
        "id": "g8zRldyND1Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_array = np.array(rgb_data)  ## converting to array"
      ],
      "metadata": {
        "id": "f4lpgxt8G5b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OA3-KNZSFXz"
      },
      "outputs": [],
      "source": [
        "## function to compute the centroid of the data\n",
        "def computeCentroid(X):\n",
        "  mean = np.mean(X, axis=0)\n",
        "  return mean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "computeCentroid(rgb_array)  ## printing the centroid of the original data"
      ],
      "metadata": {
        "id": "pS8frxXo-CrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - B"
      ],
      "metadata": {
        "id": "gaspEFEw8gnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## function to group the clusters\n",
        "def group_clusters(X, centroids):\n",
        "  dis = []\n",
        "  dis = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)  ## calculating the distances\n",
        "  groups = np.argmin(dis, axis=1)\n",
        "  return groups\n",
        "\n",
        "## functions to assign the new centroids\n",
        "def new_centroids(X,cluster_group):\n",
        "    new_cens = []\n",
        "    cluster = np.unique(cluster_group)  ## extracting the unique clusters\n",
        "    for type in cluster:\n",
        "        new_cens.append(X[cluster_group == type].mean(axis=0))\n",
        "\n",
        "    return np.array(new_cens)\n",
        "\n",
        "def mykmeans(X, no_of_clusters = 3, epochs = 1000):\n",
        "  centroids = X[random.sample(range(0,X.shape[0]),no_of_clusters)]  ## taking the random centroids\n",
        "  cluster_group = None\n",
        "  ## iterating in epochs\n",
        "  for i in range(epochs):\n",
        "        cluster_group = group_clusters(X, centroids)\n",
        "        old_centroids = centroids\n",
        "\n",
        "        # calculating the new centroid points\n",
        "        centroids = new_centroids(X,cluster_group)\n",
        "        if (old_centroids == centroids).all():\n",
        "            print('Run Completed! at epoch : ', i)\n",
        "            break\n",
        "\n",
        "  return cluster_group,centroids ## returning the cluster_group and centroids"
      ],
      "metadata": {
        "id": "N7Jcd8qY8QMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred,cluster_centroids = mykmeans(rgb_array,5)  ## running model for k = 5"
      ],
      "metadata": {
        "id": "FIUa_oOjHvRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_centroids"
      ],
      "metadata": {
        "id": "13rMCMeDJ53O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_data = rgb_array.copy()"
      ],
      "metadata": {
        "id": "epa8ZM8bKo2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - C"
      ],
      "metadata": {
        "id": "58cOKSCYJntI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "_YEwUoceNSpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.unique(y_pred):\n",
        "    rgb_data[y_pred == i] = cluster_centroids[i]"
      ],
      "metadata": {
        "id": "oQq-Pz4vJhif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image_array):\n",
        "  img_compressed = image_array.reshape(height, width , channels)\n",
        "  # creating a figure with two subplots\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "  # displaying the first image on the left subplot\n",
        "  axes[0].imshow(rgb_image)\n",
        "  axes[0].set_title('Original Image')\n",
        "\n",
        "  # displaying the second image on the right subplot\n",
        "  axes[1].imshow(img_compressed)\n",
        "  axes[1].set_title('Compressed')\n",
        "\n",
        "  # hiding the axes\n",
        "  for ax in axes:\n",
        "      ax.axis('off')\n",
        "\n",
        "  # showing the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "9xXRkM5ULWGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(rgb_data)  ## displaying the business"
      ],
      "metadata": {
        "id": "2QpTWJAaL0SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## running k-means for different value of k\n",
        "k_vals = np.arange(1, 10, 2)\n",
        "for i in k_vals:\n",
        "    y_pred,cluster_centroids = mykmeans(rgb_array,i,250)\n",
        "    rgb_data = rgb_array.copy()\n",
        "    for j in np.unique(y_pred):\n",
        "        rgb_data[y_pred == j] = cluster_centroids[j]\n",
        "    print(f'value of k is {i}')\n",
        "    show_image(rgb_data)"
      ],
      "metadata": {
        "id": "sORA9aPHOWG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## function to calculate the WCSS\n",
        "def WCSS(rgb_array, centroids, labels_):\n",
        "   wcss = 0\n",
        "   for centroid_idx, centroid in enumerate(centroids):\n",
        "       cluster_samples = rgb_array[labels_ == centroid_idx]\n",
        "       cluster_wcss = np.sum((cluster_samples - centroid) ** 2)\n",
        "       wcss += cluster_wcss\n",
        "   return wcss"
      ],
      "metadata": {
        "id": "U0mzFr5NmSs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "k_values = range(2, 10)\n",
        "wcss_scores = []\n",
        "# Performing the elbow method for the K-Means\n",
        "for k in k_values:\n",
        "    y_pred,cluster_centroids = mykmeans(rgb_array,k)\n",
        "    wcss = WCSS(rgb_array, cluster_centroids, y_pred)\n",
        "    wcss_scores.append(wcss)\n",
        "\n",
        "# Plotting WCSS scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(k_values, wcss_scores, marker='o')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.ylabel('WCSS')\n",
        "plt.title('Elbow Method')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L6fAsT4ymwJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## from the graph we can see that \"k = 6\" should be the better choice"
      ],
      "metadata": {
        "id": "_NwWBJ4jyvpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## running the k-means for k = 6\n",
        "y_pred,cluster_centroids = mykmeans(rgb_array,6)\n",
        "kmeans_centroids = cluster_centroids\n",
        "kmeans_y_pred  = y_pred"
      ],
      "metadata": {
        "id": "u7VDnH142MB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_centroids"
      ],
      "metadata": {
        "id": "Vm0FJqYnk9MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate the percentage of colors present in compressed image\n",
        "percent=[]\n",
        "labels = list(kmeans_y_pred)\n",
        "for i in range(len(kmeans_centroids)):\n",
        "  j=labels.count(i)\n",
        "  j=j/(len(kmeans_y_pred))\n",
        "  percent.append(j)\n",
        "print(percent)"
      ],
      "metadata": {
        "id": "g3BCFIVX2OPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plotting the pie chart\n",
        "plt.pie(percent,colors=np.array(kmeans_centroids/255),labels=np.arange(len(kmeans_centroids)), autopct='%1.1f%%', startangle=140)\n",
        "plt.title(\"Dominant Colors in Compressed Image using KMeans\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NKF8_GZ72O05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - D(Implementing Using SKlearn)"
      ],
      "metadata": {
        "id": "ieV5atuJ27g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans  ## importing the KMeans"
      ],
      "metadata": {
        "id": "GfrjXamQOvX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = list(np.arange(1,10, 2))"
      ],
      "metadata": {
        "id": "ZNcoNBE1hoXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## running the k-means for sklearn\n",
        "k_vals = np.arange(1, 10, 2)\n",
        "md = []\n",
        "for i in k_vals:\n",
        "    kmeans = KMeans(n_clusters = i, n_init=\"auto\")\n",
        "    s = kmeans.fit(rgb_array)\n",
        "    labels = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    md.append(kmeans.inertia_)\n",
        "    rgb_data = rgb_array.copy()\n",
        "    for j in np.unique(labels):\n",
        "        rgb_data[labels == j] = centroids[j]\n",
        "    print(f'value of k is {i}')\n",
        "    show_image(rgb_data)"
      ],
      "metadata": {
        "id": "2rog8BFI3JHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plotting the inertia vs no_of_clusters\n",
        "plt.plot(lst ,md)\n",
        "plt.xlabel(\"No of Clusters\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Inertia vs No of Clusters\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S1fZIahYhKtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## from sklearn also we can see that \"k = 6\" , would be better choice"
      ],
      "metadata": {
        "id": "KbUvVofizFvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plotting the pie chart of dominant colors using sklearn\n",
        "kmeans=KMeans(n_clusters=6, n_init=\"auto\")\n",
        "kmeans.fit(rgb_array)\n",
        "labels=kmeans.labels_\n",
        "centroid=kmeans.cluster_centers_\n",
        "labels=list(labels)\n",
        "percent=[]\n",
        "for i in range(len(centroid)):\n",
        "  j=labels.count(i)\n",
        "  j=j/(len(labels))\n",
        "  percent.append(j)\n",
        "plt.pie(percent,colors=np.array(centroid/255),labels=np.arange(len(centroid)), autopct='%1.1f%%', startangle=140)\n",
        "plt.title(\"Dominant Colors in the Compressed Image Using Sklearn\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RUjs-KMUiq8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.cluster_centers_"
      ],
      "metadata": {
        "id": "Q-KuFOP_lLNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - E"
      ],
      "metadata": {
        "id": "OdgfSVC7TNeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\"\"\"\n",
        "Code to extract the pixels along with the spatial coordinates\n",
        "\"\"\"\n",
        "image_path = 'test.png'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "image = image.convert('RGB')\n",
        "\n",
        "width, height = image.size\n",
        "\n",
        "rgb_values = []\n",
        "for y in range(height):\n",
        "    for x in range(width):\n",
        "        r, g, b = image.getpixel((x, y))\n",
        "        rgb_values.append((r, g, b, y, x))\n",
        "rgb_array_spatial = np.array(rgb_values)\n",
        "print(rgb_array_spatial.shape)\n",
        "\n",
        "\n",
        "\n",
        "def assign_clusters_sp_coh(X, centroids, spatial_weight=0.5):\n",
        "    group = []\n",
        "    # calculate the RGB distances\n",
        "    rgb_distances = np.linalg.norm(X[:, np.newaxis, :3] - centroids[:, :3], axis=2)\n",
        "    # calculate spatial distances using the last two columns (coordinates)\n",
        "    spatial_distances = np.linalg.norm(X[:, np.newaxis, 3:] - centroids[:, 3:], axis=2)\n",
        "    # combine RGB and spatial distances with the specified weight\n",
        "    combined_distances = rgb_distances + spatial_weight * spatial_distances\n",
        "    # assigning clusters based on the minimum combined distance\n",
        "    group = np.argmin(combined_distances, axis=1)\n",
        "\n",
        "    return group\n",
        "\n",
        "def move_centroids_sp_coh(X, cluster_group):\n",
        "    new_centroids = []\n",
        "\n",
        "    cluster_type = np.unique(cluster_group)\n",
        "\n",
        "    for cluster_idx in cluster_type:\n",
        "        new_centroids.append(X[cluster_group == cluster_idx].mean(axis=0))\n",
        "\n",
        "    return np.array(new_centroids)\n",
        "\n",
        "def mykmeans_sp_coh(X, n_clusters, spatial_weight=0.5):\n",
        "    max_itr = 500\n",
        "    centroids = X[random.sample(range(0, X.shape[0]), n_clusters)]\n",
        "\n",
        "    for i in range(max_itr):\n",
        "        # assigning clusters\n",
        "        cluster_group = assign_clusters_sp_coh(X, centroids, spatial_weight)\n",
        "        old_centroids = centroids\n",
        "\n",
        "        # moving centroids\n",
        "        centroids = move_centroids_sp_coh(X, cluster_group)\n",
        "\n",
        "        # checking convergence\n",
        "        if (old_centroids == centroids).all():\n",
        "            break\n",
        "\n",
        "    return cluster_group, centroids"
      ],
      "metadata": {
        "id": "py4gzAL4TRoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, group = mykmeans_sp_coh(rgb_array_spatial, 5)"
      ],
      "metadata": {
        "id": "mt3XHwVHCO3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_data_2 = rgb_array_spatial[:,:3].copy()\n",
        "for j in np.unique(labels):\n",
        "    rgb_data_2[labels == j] = group[:,:3][j]\n",
        "show_image(rgb_data_2)"
      ],
      "metadata": {
        "id": "kpnxUXhtIgvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image_coherence(image_array0, image_array1, image_array2):\n",
        "  img_compressed0 = image_array0.reshape(height, width , channels)\n",
        "  img_compressed1 = image_array1.reshape(height, width , channels)\n",
        "  img_compressed2 = image_array2.reshape(height, width , channels)\n",
        "  # Create a figure with two subplots\n",
        "  fig, axes = plt.subplots(1, 3,  figsize=(10, 5))\n",
        "\n",
        "  # Display the first image on the left subplot\n",
        "  axes[1].imshow(img_compressed1)\n",
        "  axes[1].set_title('KMeans Compressed')\n",
        "\n",
        "  # Display the second image on the right subplot\n",
        "  axes[2].imshow(img_compressed2)\n",
        "  axes[2].set_title('KMeans with Coherence Compressed')\n",
        "\n",
        "  axes[0].imshow(img_compressed0)\n",
        "  axes[0].set_title('Original Image')\n",
        "  # Hide the axes\n",
        "  for ax in axes:\n",
        "      ax.axis('off')\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rcch8iqn8JbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_vals = np.arange(2, 10, 2)\n",
        "md = []\n",
        "for i in k_vals:\n",
        "    kmeans = KMeans(n_clusters = i, n_init=\"auto\")\n",
        "    s = kmeans.fit(rgb_array)\n",
        "    labels = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    md.append(kmeans.inertia_)\n",
        "    rgb_data = rgb_array.copy()\n",
        "\n",
        "    labels1, group = mykmeans_sp_coh(rgb_array_spatial, i)\n",
        "    rgb_data_2 = rgb_array_spatial[:,:3].copy()\n",
        "    for j in np.unique(labels1):\n",
        "        rgb_data_2[labels1 == j] = group[:,:3][j]\n",
        "    # show_image(rgb_data_2)\n",
        "\n",
        "    for j in np.unique(labels):\n",
        "        rgb_data[labels == j] = centroids[j]\n",
        "    print(f'value of k is {i}')\n",
        "    show_image_coherence(rgb_array, rgb_data, rgb_data_2)"
      ],
      "metadata": {
        "id": "h-IeqSKw9XHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART - 2 (SUPPORT VECTOR MACHINE)"
      ],
      "metadata": {
        "id": "uhdBJdLzSGjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - 1(a)"
      ],
      "metadata": {
        "id": "KTQH5GlKTgiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "k9Th0NwSSKEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## loading the datasets\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris(as_frame=True)"
      ],
      "metadata": {
        "id": "__AZK4wzSLyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## extracting the data out from iris\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "QWiyFIPPSOQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target_names  ## printing the target names"
      ],
      "metadata": {
        "id": "Cm2O8ieDSR1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of y : \",y.shape) ## printing the shape of y"
      ],
      "metadata": {
        "id": "aix1ftJKSUEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X : \",X.shape) ## printing the shape of X"
      ],
      "metadata": {
        "id": "WBgEZWfwSV8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## converting X and y to array\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "y = y.reshape(-1,1)  ## reshaping the y"
      ],
      "metadata": {
        "id": "Qqcyqf7ZSZNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.concatenate((X,y), axis=1)  ## concatenating X and y"
      ],
      "metadata": {
        "id": "Uonz_NLzSh6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data, columns=[\"sepal length (cm)\", \"sepal width (cm)\",\"petal length (cm)\", \"petal width (cm)\", \"target\"])  ## creating a dataframe"
      ],
      "metadata": {
        "id": "OU36e26wSiNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() ## printing the info about datasets"
      ],
      "metadata": {
        "id": "9ia8vvn9Skhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df1 = df[df[\"target\"] == 0.00]\n",
        "new_df2 = df[df[\"target\"] == 1.00]\n",
        "new_df = pd.concat((new_df1, new_df2))"
      ],
      "metadata": {
        "id": "98NbEDrxSmd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head() ## new_df after merging the two above"
      ],
      "metadata": {
        "id": "Y1F2zOFFSuNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = new_df[[\"petal length (cm)\", \"petal width (cm)\", \"target\"]]  ## final dataset after selecting only two features"
      ],
      "metadata": {
        "id": "ZLsK9u08Surl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "pgLVNGZCSxLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = final_df.drop(columns=[\"target\"]).values\n",
        "y = final_df[\"target\"].values"
      ],
      "metadata": {
        "id": "bXZi37RaSy43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "## importing standard_scaler to scale the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "uA3HDu_1S1Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## splitting the data in the ratio of 80 : 20\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OA_ybtIvS3Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - 1(b)"
      ],
      "metadata": {
        "id": "q_4MjJz7UoAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC  ## importing the linear SVM"
      ],
      "metadata": {
        "id": "YPpvED-YS78g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## training the linear SVM\n",
        "svc = LinearSVC()\n",
        "svc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ep5sLHZyS-fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svc.predict(X_test)  ## making predictions"
      ],
      "metadata": {
        "id": "otLWU-cVTDx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "TkKbt2KtTG_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy : \",accuracy_score(y_pred, y_test))"
      ],
      "metadata": {
        "id": "UEG74rdPTHZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## defining the parameter to plot the decision boundary\n",
        "w = svc.coef_[0]\n",
        "a = -w[0] / w[1]\n",
        "xx = np.linspace(-2, 2)\n",
        "yy = a * xx - (svc.intercept_[0])/w[1]"
      ],
      "metadata": {
        "id": "Faxv0yVITJGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors import ListedColormap"
      ],
      "metadata": {
        "id": "R5_QKgcdWj_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting the decision boundary for training and test data\n",
        "\n",
        "## Training Data\n",
        "plt.plot(xx, yy)\n",
        "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)\n",
        "plt.xlabel(\"petal length (cm)\")\n",
        "plt.ylabel(\"petal width (cm)\")\n",
        "plt.title(\"Decision Boundary on Training Data\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "## Test Data\n",
        "plt.plot(xx, yy)\n",
        "plt.scatter(X_test[:,0], X_test[:,1], c=y_test)\n",
        "plt.xlabel(\"petal length (cm)\")\n",
        "plt.ylabel(\"petal width (cm)\")\n",
        "plt.title(\"Decision Boundary on Test Data\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8PKJc9XnTLGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - 2(a)"
      ],
      "metadata": {
        "id": "BJMlhEdJW2DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "QJK6q1IfCTas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=500, noise=0.05, random_state=42)  ## generating dataset using make_moons()\n",
        "\n",
        "## adding some percentage of misclassifications points\n",
        "num_noise_points = int(0.05 * len(X))\n",
        "random_indices = np.random.choice(len(X), num_noise_points, replace=False)\n",
        "y[random_indices] = 1 - y[random_indices] ## flipping the label points"
      ],
      "metadata": {
        "id": "mJdCs8bmTNE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "c55RkqumZYrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plotting the dataset\n",
        "plt.scatter(X[:,0], X[:,1], c=y)\n",
        "plt.grid(True)\n",
        "plt.title(\"Make Moons Dataset\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xSqJdnrWTQzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - 2(b)"
      ],
      "metadata": {
        "id": "Xy4q9egqXQLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "rbE1NnS2TTEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## initializing teh different kernel models\n",
        "svm_linear = SVC(kernel='linear', random_state=42)\n",
        "svm_poly = SVC(kernel='poly', degree=5, random_state=42)\n",
        "svm_rbf = SVC(kernel='rbf', gamma=0.9, random_state=42)\n",
        "\n",
        "## fitting the different SVM models\n",
        "svm_linear.fit(X, y)\n",
        "svm_poly.fit(X, y)\n",
        "svm_rbf.fit(X, y)"
      ],
      "metadata": {
        "id": "5Cs4d5l0TVDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plotting the decision boundary for different SVMs\n",
        "def plot_decision_boundary(svm_model, title):\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "    ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "    xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 100),\n",
        "                         np.linspace(ylim[0], ylim[1], 100))\n",
        "    Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_decision_boundary(svm_linear, 'Linear Kernel Plot')\n",
        "plot_decision_boundary(svm_poly, 'Polynomial Kernel Plot')\n",
        "plot_decision_boundary(svm_rbf, 'RBF Kernel Plot')"
      ],
      "metadata": {
        "id": "zlaHN0ZcTWz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - 2(c)"
      ],
      "metadata": {
        "id": "pElZVMrTXrZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Performing the GridSearchCV and RandomizedSearchCV for the \"RBF\" kernels"
      ],
      "metadata": {
        "id": "Pfav3Wjao-yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from scipy.stats import reciprocal, uniform\n",
        "## defining the parameters\n",
        "c_lst = [0.1, 0.5, 0.9, 1, 5, 10, 20, 30, 50, 100]\n",
        "g_lst = [0.001, 0.05, 0.07, 0.1, 0.5, 0.7, 0.9, 1]\n",
        "param_grid = {'C': c_lst, 'gamma': g_lst}\n",
        "## initializing the SVM using \"rbf\"\n",
        "svm_rbf_kernel = SVC(kernel='rbf')\n",
        "\n",
        "## performing the GridSearchCV\n",
        "grid_search = GridSearchCV(svm_rbf_kernel, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "## printing the best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "## evaluating the model accuracy\n",
        "best_model = grid_search.best_estimator_\n",
        "test_score = best_model.score(X_test, y_test)\n",
        "print(\"Test set accuracy:\", test_score)"
      ],
      "metadata": {
        "id": "8Ofae_3WXtt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## defining the parameters using reciprocal distribution\n",
        "param_dist = {\n",
        "    'C': reciprocal(0.1, 100),\n",
        "    'gamma': reciprocal(0.001, 1)\n",
        "}\n",
        "\n",
        "# initializing the SVM with RBF kernel\n",
        "svm = SVC(kernel='rbf')\n",
        "\n",
        "# performing the random search\n",
        "random_search = RandomizedSearchCV(svm, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# printing the best parameters\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "print(\"Best cross-validation score:\", random_search.best_score_)\n",
        "\n",
        "# evaluating the model and printing accuracy\n",
        "best_model = random_search.best_estimator_\n",
        "test_score = best_model.score(X_test, y_test)\n",
        "print(\"Test set accuracy:\", test_score)"
      ],
      "metadata": {
        "id": "aDNty9rxX7rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task - 2(d)"
      ],
      "metadata": {
        "id": "sd0SVDkRZOWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## best parameters from the GridSearchCV\n",
        "best_params = {'C': 0.5, 'gamma': 0.9}\n",
        "\n",
        "# training the svm for best parameters\n",
        "best_svm = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "best_svm.fit(X_train, y_train)\n",
        "\n",
        "# Plotting decision boundary\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                         np.arange(y_min, y_max, 0.02))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolors='k')\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_decision_boundary(best_svm, X_train, y_train)\n",
        "plt.xlabel('Petal length(cm)')\n",
        "plt.ylabel('Petal width(cm)')\n",
        "plt.title('Plot Using Best Parameters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hyf70uqMamqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## best parameters from the RandomSearchCV\n",
        "best_params = {'C': 1.3292918943162166, 'gamma': 0.711447600934342}\n",
        "\n",
        "# training the svm for best parameters\n",
        "best_svm = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "best_svm.fit(X_train, y_train)\n",
        "\n",
        "# Plotting decision boundary\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                         np.arange(y_min, y_max, 0.02))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolors='k')\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_decision_boundary(best_svm, X_train, y_train)\n",
        "plt.xlabel('Petal length (cm)')\n",
        "plt.ylabel('Petal width (cm)')\n",
        "plt.title('Plot Using Best Parameters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dgXdElV_Yqxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhKMbfi6ZH22"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}